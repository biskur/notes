# 引言
## 概念
**模式识别**(pattern recognition)领域关注的是通过使用计算机算法自动发现数据中的规律性，并利用这些规律性采取诸如将数据分为不同类别等行动。
通过采用**机器学习**(machine learning)的方法可以得到更好的结果，在这种方法中，大量的$N$个数字集$\bf{x}=\{x_1, \cdots, x_N\}$被称为**训练集**(training set)，用于调整自适应模型的参数。训练集中数据的类别事先已知，通常是通过对它们进行单独检查和手工标注，形成**目标向量**(target vector)$\bf{t}$。我们可以用目标向量$t$来表示一个数字的类别，它代表了相应数字的身份。
运行机器学习算法的结果可以表示为一个函数$\bf{y}(\bf{x})$，输出向量的编码方式与目标向量相同。确定函数$\bf{y}(\bf{x})$的精确形式是在**训练阶段**(training phase)，也叫**学习阶段**(learning phase)。一旦模型经过训练，它就可以确定新数字图像的身份，这些图像被称为构成**测试集**(test set)。对不同于训练所用的新例子进行正确分类的能力被称为**泛化**(generalization)。在实际应用中，输入向量的可变性将使训练数据只能包含所有可能的输入向量中的一小部分，因此泛化是模式识别的一个核心目标。
对于大多数的实际应用来说，原始的输入变量通常会被预处理，以将其转化为一些新的变量空间。预处理阶段有时也被称为**特征提取**(feature extraction)。
训练数据包括输入向量的例子和相应的目标向量的应用被称为**监督学习**(supervised learning)。像数字识别这样的例子，其目的是将每个输入向量分配到有限数量的离散类别中的一个，被称为**分类**(classification)问题。如果所需的输出由一个或多个连续变量组成，那么这个任务就被称为**回归**(regression)问题。回归问题的一个例子是化学生产过程中产量的预估，其中输入包括反应物的浓度、温度和压力。
在其他模式识别问题中，训练数据由一组没有任何对应目标值的输入向量$\bf{x}$组成。在这种**无监督学习**(unsupervised learning)问题中，目标可能是在数据中发现类似的样例组，这称为**聚类**(clustering)，或者确定数据在输入空间中的分布，称为**密度估计**(density estimation)，或者为了**可视化**(visualization)的目的，将数据从高维空间投射到二维或三维空间。
与监督学习不同的是，**强化学习**(reinforcement learning)算法并没有得到最佳输出的例子，而是必须通过试错的过程来发现它们。通常情况下，学习算法与环境的互动有一个状态和动作的序列。在许多情况下，当前的动作不仅影响到眼前的奖励，而且还对所有后续时间步长的奖励产生影响。强化学习的一个普遍特征是在**探索**(exploration)和**利用**(exploitation)之间进行权衡，前者是系统尝试新的行动，看看它们的效果如何，后者是系统利用已知的高回报行动。过于注重探索或利用都会产生不良结果。
如果想让机器学习技术在实际应用中发挥最大作用的话，必须要清楚地理解三个重要工具：**概率论**(probability theory)、**决策论**(decision theory)、**信息论**(information theory)。
## 以多项式拟合为例
以多项式拟合为例，现在我们考虑$x$的$N$个观测量组成的向量，记作$\bf{x}\equiv(x_1,\cdots,x_N)^T$，和对应的目标变量，记作$\bf{t}\equiv(t_1,\cdots,t_N)^T$。我们的目标是利用这个训练集，以便对输入变量的某个新值$\hat{x}$进行目标变量值t的预测。观察到的数据被噪声污染，因此对于给定的$\hat{x}$，合适的$\hat{t}$也是不确定的。概率论提供了一个以精确和定量的方式表达这种不确定性的框架，而决策论允许我们利用这种概率表示，以便根据适当的标准做出最优的预测。
目前我们将并考虑一种基于曲线拟合的简单方法，使用一个多项式函数来拟合数据，其形式为
$$y(x,\bf{w})=w_0+w_1x+w_2x^2+\cdots+w_Mx^M=\sum_{j=0}^{M}w_jx^j$$
其中$M$是多项式的**阶数**(order)，$x^j$表示$x$的$j$次幂，多项式的系数$w_0,\cdots,w_M$统称为向量$\bf{w}$。注意，多项式函数$y(x,\bf{w})$虽然是$x$的非线性函数，但它是系数$\bf{w}$的线性函数，未知参数为线性的多项式等函数具有重要的性质，称为**线性模型**(linear model)。
系数的值将通过对训练数据拟合多项式来确定。这可以通过最小化一个**误差函数**(error function)来实现，该误差函数衡量函数$y(x,\bf{w})$与训练集数据点之间的拟合度，对于任何给定的$\bf{w}$值而言。一个简单而广泛使用的误差函数是由每个数据点$x_n$的预测$y(x_n,\bf{w})$和相应的目标值$t_n$之间的误差的平方和给出，因此我们最小化
$$E(\bf{w})=\cfrac12\sum_{n=1}^{N}\{y(x_n,\bf{w}-t_n)\}^2$$
其中因子$1/2$是为了以后方便处理。
我们可以通过选择$\bf{w}$的值，使$E(\bf{w})$尽可能小来解决曲线拟合问题。由于误差函数是系数$\bf{w}$的二次函数，其相对于系数的导数将在$\bf{w}$的元素中呈线性，因此误差函数的最小化有一个唯一解，用$\bf{w}^\star$表示，可以用封闭形式找到。所得多项式由函数$y(x,\bf{w}^\star)$给出。
剩下的问题是如何选择多项式的阶数，这是一个被称为**模型对比**(model comparison)或**模型选择**(model selection)的重要概念的一个例子。
常数($M=0$)和一阶($M=1$)多项式对数据的拟合度很差，三阶($M=3$)多项式似乎对函数的拟合度最好。当采用更高阶的多项式($M=9$)时，获得了对训练数据的极好拟合。事实上，多项式精确地通过每个数据点，并且$E(\bf{w}^\star)=0$。然而，拟合的曲线疯狂地摆动，并给出了一个非常糟糕的函数$\sin(2πx)$表示。这被称为**过度拟合**(over-fitting)。
测试集误差衡量我们在预测$x$的新数据观测值$t$的数值方面做得如何。
对于给定的模型复杂性，随着数据集规模的增加，过度拟合问题变得不那么严重。另一种说法是，数据集越大，我们能承受的数据拟合模型越复杂，换句话说就是越灵活。有时提倡的一个粗略的启发式方法是，数据点的数量不应少于模型中自适应参数数量的某个倍数，比如5或10。
另外，根据可用训练集的大小来限制模型中的参数数量，这一点也是相当令人不满意的。根据所要解决的问题的复杂程度来选择模型的复杂程度似乎更为合理。我们将看到，最小二乘法寻找模型参数的方法代表了**最大似然**(maximum likelihood)的一种特殊情况，而过拟合问题可以理解为最大似然的一般属性。通过采用**贝叶斯**(Bayesian)方法，可以避免过拟合问题。我们将看到，从贝叶斯的角度来看，采用参数数量大大超过数据点数量的模型并不困难。在贝叶斯模型中，参数的**有效**(effective)数量会自动适应数据集的大小。
经常用来控制过拟合现象的一种技术是**正则化**(regularization)技术，即在误差函数中加入一个惩罚项，以阻止系数达到大值。最简单的惩罚项的形式是所有系数的平方和，因而修改后的误差函数的形式为
$$\tilde{E}(\bf{w})=\cfrac12\sum_{n=1}^N\{y(x_n,\bf{w}-t_n)\}^2+\cfrac{\lambda}{2}\|\bf{w}\|^2$$
其中，$\|\bf{w}\|^2\equiv\bf{w}^T\bf{w}=w_0^2+w_1^2+\cdots+w_M^2$，系数$λ$控制着正则化项与二乘法误差项的相对重要性。需要注意的是，正则化器中通常会省略系数$w_0$，因为它的加入会导致结果取决于目标变量的原点选择，或者它可能被包括在内，但有自己的正则化系数。同样，误差函数可以完全以闭合形式最小化。像这样的技术在统计学文献中被称为**收缩**(shrinkage)法，因为它们减少了系数的值。平方正则化器的特殊情况被称为**脊回归**(ridge regression)。在神经网络的背景下，这种方法被称为**权衰减**(weight decay)。
模型复杂度的问题是一个重要的问题，如果我们试图用这种最小化误差函数的方法来解决实际应用，我们就必须找到一种方法来确定模型复杂度的合适值。上面的结果提出了一个简单的实现方法，即把现有的数据分割成一个训练集，用来确定系数$\bf{w}$，和一个单独的验证集，也称为**保留**(hold-out)集，用来优化模型复杂度($M$或$λ$)。然而，在很多情况下，这将被证明太浪费宝贵的训练数据，必须寻求更复杂的方法。
## 概率论
设有两个随机变量，$X$可以取$x_i$中任意值，其中$i=1,\cdots,M$，$Y$可以取$y_j$中任意值，其中$j=1,\cdots,L$。考虑总共有$N$次试验，在这些试验中，我们对变量$X$和$Y$都进行了抽样，并让$X=x_i$和$Y=y_j$的试验次数为$n_{ij}$。另外，让$X$取值$x_i$(不管$Y$取值多少)的试验次数用$c_i$表示，同样让$Y$取值$y_j$的试验次数用$r_j$表示。$X$取值$x_i$且$Y$取值$y_j$的概率记为$p(X=x_i,Y=y_j)$，称为**联合**(joint)概率。它由落在单元$i,j$中的点数占总点数的比例给出。
$$p(X=x_i,Y=y_j)=\cfrac{n_{ij}}{N}$$
这里我们隐含地考虑了极限$N\to∞$。同样，不管$Y$的值如何，$X$取值$x_i$的概率写成
$p(X=x_i)$并由落在第$i$列中的点总数的分数给出，故而$$p(X=x_i)=\cfrac{c_i}{N}$$
我们有$c_i=\sum_{j}n_{ij}$因此
$$p(X=x_i)=\sum_{j=1}^Lp(X=x_i,Y=y_j)$$
这就是概率的**求和规则**(sum rule)。请注意，$p(X=x_i)$有时也被称为**边缘**(marginal)概率，因为它是通过边缘化或求和其他变量(在本例中为$Y$)得到的。
如果我们只考虑那些$X=x_i$的实例，那么这些实例中$Y=y_j$的部分就写成$p(Y=y_j|X=x_i)$，并称为给定$X=x_i$下$Y=y_j$的**条件**(conditional)概率。它是通过找到第$i$列中落在单元格$i,j$中的那些点的分数而得到的，因此由以下公式给出
$$p(Y=y_j|X=x_i)=\cfrac{n_{ij}}{c_i}$$
由此推得
$$p(X=x_i,Y=y_j)=p(Y=y_j|X=x_i)p(X=x_i)$$
这就是概率的**求积规则**(product rule)。
采用简记符号则是
> 求和规则$p(X)=\sum_Yp(X,Y)$

> 求积规则$p(X,Y)=p(Y|X)p(X)$

从求积规则出发，加上对称性$p(X,Y)=p(Y,X)$，我立即得到条件概率之间的关系如下所示
$$p(Y|X)=\cfrac{p(X|Y)p(Y)}{p(X)}$$
这就是所谓的**贝叶斯定理**(Bayes' theorem)，它在模式识别和机器学习中起着核心作用。利用求和规则，贝叶斯定理中的分母可以用分子中出现的数量来表示
$$p(X)=\sum_Yp(X|Y)p(Y)$$
我们可以把贝叶斯定理中的分母看作是确保贝叶斯定理式子左侧条件概率对所有$Y$值的总和等于1所需的归一化常数。
观测之前得到的概率是**先验概率**(prior probability)，观测之后得到的概率是**后验概率**(posterior probability)。
如果两个变量的联合分布因子化为边缘的乘积，如$p(X,Y)=p(X)p(Y)$，那么就可以说$X$和$Y$**独立**(independent)。从求积规则可以看出，$p(Y|X)=p(Y)$，所以给定$X$的$Y$的条件分布确实与$X$的值无关。

如果一个实值变量$x$落在区间$(x,x+δx)$的概率由$p(x)δx$给出，对$δx\to 0$，那么$p(x)$称为$x$上的**概率密度**(probability density)。$x$位于区间$(a,b)$的概率由以下公式给出
$$p(x\in(a,b))=\int_a^bp(x)dx$$
因为概率是非负数，而且$x$的值必须位于实轴的某一位置，所以概率密度$p(x)$必须满足两个条件
$$\begin{aligned}p(x)&\geq 0\\\int_{-\infty}^\infty p(x)dx&=1\end{aligned}$$
$x$位于区间$(-∞,z)$的概率由**累积分布**(cumulative distribution)函数给出，定义为
$$P(z)=\int_{-\infty}^z p(x)dx$$
其中满足$P^\prime(x)=p(x)$
如果我们有几个连续变量$x_1,\cdots,x_D$，统称为向量$\bf{x}$。那么可以定义一个联合概率密度$p(\bf{x})=p(x_1,\cdots,x_D)$，使得$\bf{x}$落在包含点$\bf{x}$的无限小体积$δ\bf{x}$中的概率由$p(\bf{x})δ\bf{x}$给出。这个多元概率密度必须满足
$$\begin{aligned}p(\bf{x})&\geq 0\\\int p(\bf{x})d\bf{x}&=1\end{aligned}$$
其中，积分是在整个$\bf{x}$空间上进行的。也可以考虑在离散变量和连续变量组合上的联合概率分布。
注意，如果$\bf{x}$是一个离散变量，那么$p(x)$有时被称为**概率质量函数**(probability mass function)，因为它可以被看作是一组集中在$x$的允许值上的概率质量。连续变量的求和与求积规则的形式化论证需要数学的一个分支，称为**测度论**(measure theory)。
某函数$f(x)$在概率分布$p(x)$下的平均值称为$f(x)$的**期望**(expextation)，用$\Bbb{E}[f]$表示。对于一个离散分布，它由以下公式给出
$$\Bbb{E}[f]=\sum_x p(x)f(x)$$
因此，平均值由$x$的不同值的相对概率加权。在连续变量的情况下，期望以相应概率密度的积分表示
$$\Bbb{E}[f]=\int p(x)f(x)dx$$
有时我们会考虑多个变量的函数期望值，在这种情况下，可以使用下标来表示哪个变量被平均，因此例如
$$\Bbb{E}_x[f(x,y)]$$
表示函数$f(x,y)$相对于$x$的分布的平均值。注意$\Bbb{E}_x[f(x,y)]$将是$y$的函数。我们还可以考虑一个关于条件分布的**条件期望**(conditional expectation)，那么
$$\Bbb{E}_x[f|y]=\sum_x p(x|y)f(y)$$
对连续变量有一个类似的定义。
函数$f(x)$的**方差**(variance)定义为
$$\rm{var}[f]=\Bbb{E}[(f(x)-\Bbb{E}[f(x)])^2]$$
并提供了一个衡量$f(x)$围绕其平均值$\Bbb{E}[f(x)]$的变异程度的方法。将平方展开，方差也可以写成$f(x)$和$f(x)^2$的期望值项
$$\rm{var}[f]=\Bbb{E}[f(x)^2]-\Bbb{E}[f(x)]^2$$
对于两个随机变量$x$和$y$，其**协方差**(covariance)定义为
$$\rm{cov}[x,y]=\Bbb{E}_{x,y}[\{x-\Bbb{E}[x]\}\{y-\Bbb{E}[y]\}]=\Bbb{E}_{x,y}[xy]-\Bbb{E}[x]\Bbb{E}[y]$$
它表示$x$和$y$一起变化的程度。如果$x$和$y$是独立的，那么它们的协方差就会消失。
在两个随机变量向量$\bf{x}$和$\bf{y}$的情况下，协方差是一个矩阵
$$\rm{cov}[\bf{x},\bf{y}]=\Bbb{E}_{\bf{x},\bf{y}}[\{\bf{x}-\Bbb{E}[\bf{x}]\}\{\bf{y}^T-\Bbb{E}[\bf{y}^T]\}]=\Bbb{E}_{\bf{x},\bf{y}}[\bf{x}\bf{y}^T]-\Bbb{E}[\bf{x}]\Bbb{E}[\bf{y}^T]$$
## 贝叶斯概率
到目前为止，我们是以随机的、可重复的事件的频率来看待概率的。称为概率的经典或频率主义解释。更普遍的贝叶斯观点认为概率是对不确定性的量化。考虑前面讨论的多项式曲线拟合的例子。将概率的频率主义概念应用于观测变量$t_n$的随机值似乎是合理的，但我们希望解决和量化围绕着模型参数$\bf{w}$的适当选择的不确定性。从贝叶斯的角度来看，可以使用概率论的机制来描述模型参数的不确定性，比如$\bf{w}$，或者说模型本身的选择。
贝叶斯定理是通过结合观测数据提供的证据，将先验概率转化为后验概率。在对诸如多项式曲线拟合例子中的参数$\bf{w}$等量进行推断时，可以采用类似的方法。在观察数据之前，我们以先验概率分布$p(\bf{w})$的形式来捕捉我们对$\bf{w}$的假设。观察到的数据$\cal{D}={t_1,\cdots,t_N}$通过条件概率$p(\cal{D}|\bf{w})$来表示，贝叶斯定理，其形式为
$$p(\bf{w}|\cal{D})=\cfrac{p(\cal{D}|\bf{w})p(\bf{w})}{p(\cal{D})}$$
然后允许我们以后验概率$p(\bf{w}|\cal{D})$的形式来评估观察到$\cal{D}$后$\bf{w}$的不确定性。
贝叶斯定理右侧的量$p(\cal{D}|\bf{w})$是针对观察到的数据集$\cal{D}$进行评估的，可以看作是参数向量$\bf{w}$的函数，在这种情况下，它被称为**似然函数**(likelihood function)。它表示在参数向量$\bf{w}$的不同设置下，观察到的数据集的概率有多大。注意，似然不是$\bf{w}$的概率分布，它相对于$\bf{w}$的积分并不(一定)等于1。
考虑到这个似然的定义，我们可以用文字来说明贝叶斯定理
$$\text{后验}∝\text{似然}×\text{前验}$$
式中所有的量看作$\bf{w}$的函数。分母是归一化常数，它保证了左手边的后验分布是有效的概率密度且积分为1。事实上，将式子两边关于$\bf{w}$积分，可以将贝叶斯定理中的分母用先验分布和似然函数来表示
$$p(\cal{D})=\int p(\cal{D}|\bf{w})p(\bf{w})d\bf{w}$$
在贝叶斯和频率主义范式中，似然函数$p(\cal{D}|\bf{w})$都起着核心作用。然而，这两种方法中的使用方式是根本不同的。在频率主义中，$\bf{w}$被认为是一个固定的参数，其值由某种形式的“估计器”决定，而这个估计的误差条是通过考虑可能的数据集$\cal{D}$的分布获得的。相反，从贝叶斯的观点来看，只有一个数据集$\cal{D}$(即实际观察到的数据集)，而参数的不确定性是通过对$\bf{w}$的概率分布来表示的。
一个广泛使用的频率主义估计器是**最大似然**(maximum likelihood)，其中$\bf{w}$被设置为最大化似然函数$p(\cal{D}|\bf{w})$的值。这相当于选择观测数据集的概率最大化的$\bf{w}$的值。在机器学习文献中，似然函数的负对数被称为**误差函数**(error function)。由于负对数是一个单调减函数，所以最大化似然等于最小化误差。
## 高斯分布
对于单个实值变量$x$的情况，**高斯分布**(Gaussian distribution)的定义为
$$\cal{N}(x|μ,σ^2)=\cfrac{1}{(2πσ^2)^{1/2}}\exp\left(-\cfrac{1}{2σ^2}(x-μ)^2\right)$$
它由两个参数控制：$μ$称为**均值**(mean)，$σ^2$称为**方差**(variance)。由$σ$给出的方差的平方根称为**标准差**(standard deviation)，方差的倒数写成$β=1/σ^2$称为**精度**(precision)。
$x$的平均值由下式给出
$$\Bbb{E}[x]=\int_{-\infty}^\infty\cal{N}(x|μ,σ^2)xdx=μ$$
其二阶矩则是
$$\Bbb{E}[x^2]=\int_{-\infty}^\infty\cal{N}(x^2|μ,σ^2)xdx=μ^2+σ^2$$
因而$x$的方差是
$$\rm{val}[x]=\Bbb{E}[x^2]-\Bbb{E}[x]^2=σ^2$$
我们也对$D$维连续变量的向量$\bf{x}$的高斯分布也感兴趣
$$\cal{N}(\bf{x}|\bf{μ},\bf{Σ})=\cfrac{1}{(2π)^{D/2}}\cfrac{1}{|\bf{Σ}|^{1/2}}\exp\left(-\cfrac12(\bf{x}-\bf{μ})^T\bf{Σ}^{-1}(\bf{x}-\bf{μ})\right)$$
其中$D$维向量$\bf{μ}$称为均值，$D\times D$矩阵$\bf{Σ}$称为协方差，$|\bf{Σ}|$表示$\bf{Σ}$的行列式。
现在假设我们有一个观测数据集$\sf{x}=(x_1,\cdots,x_N)^T$，代表标量变量$x$的$N$个观测值。注意使用字型$\sf{x}$来区别于向量值变量$(x_1,\cdots,x_D)^T$的单个观测值，后者用$\bf{x}$来表示。假设观测值是从一个高斯分布中独立抽取的，该分布的均值$μ$和方差$σ^2$是未知的，我们希望从数据集中确定这些参数。从同一分布中独立抽取的数据点被称为**独立同分布**(independent and identically distributed)，通常简称为i.i.d。两个独立事件的联合概率由每个事件分别的边缘概率的乘积给出。由于我们的数据集$\sf{x}$满足i.i.d.，因此可以将给定$μ$和$σ^2$的数据集的概率写成以下形式
$$p(\sf{x}|μ,σ^2)=\prod_{n=1}^N\cal{N}(x_n|μ,σ^2)$$
利用观察到的数据集确定概率分布中的参数，一个常用的标准是找到使似然函数最大化的参数值。我们将通过最大化似然函数来确定高斯中未知参数$μ$和$σ^2$的值。在实际操作中，最大化似然函数的对数更为方便。因为对数是其参数的单调递增函数，函数对数的最大化相当于函数本身的最大化。取对数不仅可以简化后续的数学分析，而且在数值上也有帮助，因为大量小概率的乘积很容易使计算机的数值精度不足，这时可以改用计算对数概率的和来解决。
$$\ln p(\sf{x}|μ,σ^2)=-\cfrac{1}{2σ^2}\sum_{n=1}^N(x_n-μ)^2-\cfrac{N}{2}\ln σ^2-\cfrac{N}{2}\ln(2π)$$
将上式与$μ$的关系最大化，我们得到的最大似然解为
$$μ_{\text{ML}}=\cfrac{1}{N}\sum_{n=1}^N x_n$$
即为**样本均值**(sample mean)，即观测值$\{x_n\}$的均值。同样，将其相对于$σ^2$最大化，我们得到方差的最大似然解，其形式为
$$σ^2_{\text{ML}}=\cfrac{1}{N}\sum_{n=1}^N(x_n-μ_{\text{ML}})^2$$
这是相对于样本平均值$μ_\text{ML}$的**样本方差**(sample variance)，这是一个有偏估计。请注意，我们正在对$μ$和$σ^2$进行的联合最大化，但在高斯分布的情况下，$μ$的解与$σ^2$的解是解耦的。
最大似然法系统地低估了方差，这就是所谓的**偏差**(bias)现象的一个例子。很容易证明
$$\begin{aligned}&\Bbb{E}[μ_\text{ML}]=μ\\&\Bbb{E}[σ^2_\text{ML}]=\left(\cfrac{N-1}{N}\right)σ^2\end{aligned}$$
因而无偏估计的方差应该是
$$\tilde{σ}^2=\cfrac{N}{N-1}σ^2_{\text{ML}}=\cfrac{1}{N-1}\sum_{n=1}^N(x_n-μ_\text{ML})^2$$
需要注意的是，随着数据点数量$N$的增加，最大似然解的偏差越来越小，在极限$N\to ∞$时，方差的最大似然解等于产生数据的分布的真实方差。
## 再以多项式拟合为例：贝叶斯方法
曲线拟合问题的目标是能够根据一组由$N$个输入值$\sf{x}=(x_1,\cdots,x_N)^T$及其对应的目标值$\sf{t}=(t_1,\cdots,t_N)$所组成的训练数据，给定输入变量$x$的某个新值，对目标变量$t$进行预测。可以用一个概率分布来表达我们对目标变量值的不确定性。为此，我们将假设，给定$x$的值，$t$的相应值具有高斯分布。因此，我们有
$$p(t|x, \bf{w},β)=\cal{N}(t|y(x,\bf{w}),β^{-1})$$
其中定义了一个精度参数$β$，对应于分布的逆方差，$β^{-1}=σ^2$。
现在我们使用训练数据$\{\sf{x},\sf{t}\}$通过最大似然来确定未知参数$\bf{w}$和$β$的值。如果假设数据是独立抽取的，那么似然函数由以下公式给出
$$p(\sf{t}|\sf{x},\bf{w},β)=\prod_{n=1}^N\cal{N}(t_n|y(x_n,\bf{w}),β^{−1})$$
转为对数似然函数，代入高斯分布，则
$$\ln p(\sf{t}|\sf{x},\bf{w},β)=-\cfrac{β}{2}\sum_{n=1}^N\left(y(x_n,\bf{w})-t_n\right)^2+\cfrac{N}{2}\ln β-\cfrac{N}{2}\ln(2π)$$
我们接下来要确定多项式系数的最大似然解$\bf{w}_\text{ML}$和高斯分布精度参数的最大似然解$β_\text{ML}$。对于$\bf{w}_\text{ML}$，可以省略上式右边不依赖于$\bf{w}$的最后两个项。此外，注意到用正的常系数来缩放对数似然不会改变$\bf{w}$最大值的位置，所以可以用$1/2$来代替系数$β/2$。最后，我们可以不最大化对数似然，而是等价地最小化负对数似然。因此我们看到，就确定$\bf{w}$而言，最大化似然相当于最小化由
$$E(\bf{w})=\cfrac12\sum_{n=1}^{N}\{y(x_n,\bf{w}-t_n)\}^2$$
定义的平方和误差函数。因此，在高斯噪声分布的假设下，作为最大化似然的结果，出现了平方和误差函数。
同样，对于$β_\text{ML}$，关于$β$最大化对数似然函数，得到
$$\cfrac{1}{β_\text{ML}}=\cfrac{1}{N}\sum_{n=1}^N\left(y(x_n,\bf{w}_\text{ML}),t_n\right)^2$$
同样，我们可以首先确定管理平均数的参数向量$\bf{w}_\text{ML}$，然后用它来找到精度$β_\text{ML}$，就像简单的高斯分布那样。
确定了参数$\bf{w}$和$β$之后，现在可以对x$的$新值进行预测。因为已经有了一个概率模型，所以我们可以用**预测分布**(predictive distribution)来表示，它给出了$t$的概率分布，而不是简单的点估计，并通过将最大似然参数代回得到
$$p(t|x, \bf{w}_\text{ML},β_\text{ML})=\cal{N}(t|y(x,\bf{w}_\text{ML}),β^{-1}_\text{ML})$$
现在，让我们向贝叶斯方法更迈进一步，并在多项式系数$\bf{w}$上引入一个先验分布。为了简单起见，考虑高斯分布，其形式为
$$p(\bf{w}|α)=\cal{N}(\bf{w}|\bf{0},α^{-1}\bf{I})=\left(\cfrac{α}{2π}\right)^{(M+1)/2}\exp\left(-\cfracα2\bf{w}^T\bf{w}\right)$$
其中$α$为分布的精度，$M+1$为$M$阶多项式的向量$\bf{w}$的元素总数。$α$等控制模型参数分布的变量称为**超参数**(hyperparameter)。利用贝叶斯定理，$\bf{w}$的后验分布正比于先验分布和似然函数的乘积
$$p(\bf{w}|\sf{x},\sf{t},α,β)∝p(\sf{t}|\sf{x},\bf{w},β)p(\bf{w}|α)$$
现在，我们可以通过找到给定数据中$\bf{w}$的最可能值来确定$\bf{w}$，换句话说，通过最大化后验分布来确定。这种技术被称为**最大后验**(maximum posterior)，或者简称为MAP。后验的最大值由下列各项的最小值给出
$$\cfracβ2\sum_{n=1}^N\left(y(x_m,\bf{w})-t_n\right)^2+\cfracα2\bf{w}^T\bf{w}$$
因此我们看到，最大化后验分布相当于最小化前面遇到的正则化的平方和误差函数的形式，正则化参数由$λ=α/β$给出。
虽然我们已经包含了一个先验分布$p(\bf{w}|α)$，但到目前为止，仍是在对$\bf{w}$进行点估计，所以还不能算是贝叶斯的处理方法。在一个完全贝叶斯的方法中，应该始终如一地应用概率的求和与求积规则，这就要对$\bf{w}$的所有值进行积分，这种边缘化是模式识别贝叶斯方法的核心。
贝叶斯的处理方法简单来说就是对应于概率的求和与求积规则的一致应用，使得预测分布可以写成以下形式 
$$p(t|x,\sf{x},\sf{t})=\int p(t|x,\bf{w})p(\bf{w}|\sf{x},\sf{t})d\bf{w}$$
这里的$p(t|x,\bf{w})$省略了对$α$和$β$的依赖，以简化符号。这里$p(\bf{w}|\sf{x},\sf{t})$是参数上的后验分布。对于像曲线拟合这样的问题，这个后验分布是一个高斯分布，并可以通过分析来评估。同样地，上式中的积分也可以用分析的方法进行，其结果是预测分布是由以下形式的高斯给出的
$$p(t|x,\sf{x},\sf{t})=\cal{N}(t|m(x),s^2(x))$$
其中均值和方差由下列给出
$$\begin{aligned}&m(x)=βφ(x)^T\bf{S}\sum_{n=1}^Nφ(x_n)t_n\\&s^2(x)=β^{−1}+φ(x)^T\bf{S}φ(x)\end{aligned}$$
矩阵$\bf{S}$满足
$$\bf{S}^{−1}=α\bf{I}+β\sum_{n=1}^Nφ(x_n)φ(x)^T$$
其中$\bf{I}$为单位矩阵，对于$i=0,\cdots,M$，我们定义了元素为$φ_i(x)=x^i$的向量$φ(x)$。
## 模型选择
如果数据丰富，可以简单地使用一些可用的数据来训练一系列的模型，或者使用给定的模型的复杂度参数的一系列值，然后在独立的数据上比较它们，有时称为**验证集**(validation set)，并选择具有最佳预测性能的模型。如果模型设计使用有限大小的数据集进行多次迭代，那么对验证数据可能会出现一些过拟合，因此可能有必要保留第三个**测试集**(test set)，对所选模型的性能进行最终评估。如果验证集很小，将会给出一个相对更有噪声的预测性能估计。解决这一难题的一个办法是使用**交叉验证**(cross-validation)。这样可以将可用数据中的一部分$(S-1)/S$用于训练，同时利用所有数据来评估性能。当数据特别稀少时，可能适合考虑$S=N$，其中$N$是数据点的总数，这就给出了**留一**(leave-one-out)技术。
虽然**维度诅咒**(curse of dimensionality)肯定会给模式识别应用带来重要的问题，但它并不妨碍我们找到适用于高维空间的有效技术。原因有二。首先，真实数据通常会被限制在一个有效维度较低的空间区域，特别是目标变量发生重要变化的方向可能会被限制。其次，真实数据通常会表现出一些平滑性的特性(至少是局部的)，因此在大多数情况下，输入变量的微小变化会在目标变量中产生微小的变化，因此我们可以利用类似局部插值的技术，使我们能够对输入变量的新值进行目标变量的预测。成功的模式识别技术利用了其中的一个或两个特性。
## 决策论
决策论的主题：在给定合适的概率下，做出最优的选择。